%\VignetteEngine{knitr::knitr}
%\VignetteIndexEntry{Case Study: estimation after blinded interim estimations}
\documentclass{article}


\usepackage{colortbl}
\usepackage{booktabs}
\newcommand{\ie}{{\em i.e.,~}}
\begin{document}

\section{Introduction}

This vignette reruns the simulations shown in the case study of our
paper. Running the simulations for the case study requires some
additional packages. Most notably \texttt{bt88.03.704} which can be
installed from github using \texttt{install\_github} from package
\texttt{devtools}.

<<instalBT88,eval=F>>=

library(devtools)
install_github('floatofmath/bt88.03.704')

@ 


<<loadstuff,include=F,echo=F>>=

library(blindConfidence)
library(parallel)
library(ggplot2)
library(bt88.03.704)
options(mc.cores=pmax(1,detectCores()-2))

@ 

The next code chunk runs the simulations. This may take a several of
hours to a couple of days depending on the machine you run them
on. Here with 32 cores and 32GB ram it took about 2 hours. 

We first set up the parameters from \cite{kieser2003} and then run the
simulation.

<<Settings,echo=F>>=

alpha = 0.025
beta = 0.2
d = 5.5
s = 8

n1 <- 15
s1o <- 6
s1a <- 5.3
@

<<Simulation,eval=F>>=

set.seed(659376)
G <- expand.grid(delta = round(seq(-2*d, 2*d,d/20),2),sigma = round(seq(1,20,1)),d=5.5,s=8,n1=15)

runs=10^6
casesim <- t(simplify2array(mclapply(1:nrow(G),function(i) {c(G[i,],simVBIA(delta=G[i,]$delta,sigma=G[i,]$sigma,d=G[i,]$d,s=G[i,]$s,n1=G[i,]$n1,cf=1,runs=runs,alpha=.025,beta=.2))})))

runs <- 10^5
bsim <- do.call(rbind,lapply(1:nrow(G),function(i) {c(G[i,],simMBIA(delta=G[i,]$delta,sigma=G[i,]$sigma,n1=dsim[i,]$n1,runs=runs))}))

load('fallback.rda')
bsim <- as.data.frame(apply(bsim,2,unlist),row.names=NA)

pN <- 2*ceiling(zss(s,d,alpha,beta))

gsim <- as.data.frame(t(apply(casesim,1,unlist)))

gsim$var.rbias <- gsim$variance.bias/gsim$sigma^2
gsim$bound <- lowerBound(gsim$n1,gsim$d)
gsim$mean.upper.bias <- bsim$m.bias
gsim$mean.lower.bias <- bsim$m.bias.n
casesim <- gsim


print(fname <- paste('casesim_',format(Sys.time(),"%y%m%d"),'.Rd',sep=''))
save(casesim,file=fname)

@




\section{Case study}


As an example \cite{Kieser03} present the trial reported in
\cite{Malsch01}, which is a randomized placebo controlled trial of
the efficacy of the kava-kava special extract "WS$^{\textregistered}$
1490" for the treatment of anxiety. The primary endpoint of the study
was the change in the Hamilton Anxiety Scale (HAMA) between baseline
and end of treatment. Assuming a mean difference between treatment and
control of $\delta_0 = \Sexpr{d}$ and standard deviation of $\sigma_0
= 8$ (\ie a variance of $\sigma_0^2=64$) results in a sample size of
$34$ patients per group to provide a power of $80\%$.

<<maxVarbias,include=F,echo=F>>=

variance.bias <- lowerBound(n1,d,alpha,beta)

@ 



<<include=F,echo=F>>=
data('casesim')


require(ggplot2)

max.mean.bias <- max(casesim$mean.bias)
uc.max.mean.bias <- max(casesim$uc.mean.bias)
min.mean.bias <- min(casesim$mean.bias)
uc.min.mean.bias <- min(casesim$uc.mean.bias)

max.var.bias <- min(casesim$variance.bias)
uc.max.var.bias <- min(casesim$uc.variance.bias)

#$
@ 

\cite{Kieser03} assume that sample size reassessment based on
blinded data is performed after $15$ patients per group and consider 
that the interim estimate of the standard deviation is $S_{1,OS} =
6$ and adjusting for $\delta_0 = 5.5$ gives
$S_{1,OS,\delta_0}=5.3$. The corresponding updated sample sizes are
then given by 19 and 15 patients (per group), respectively. In an
unrestricted desgin, an additional 4 patients per group would have 
been recruited based on $S_{1,OS}$; the trial would have been stopped
early based on $S_{1,OS,\delta_0}$.

If the sample size reassessment is based on the unadjusted interim
variance estimate $S_{1,OS}$, the variance estimate from the completed
trial will be negatively biased. Theorem \ref{the:bound} gives a lower
bound for the magnitude of that bias which in this case is
$\Sexpr{round(variance.bias,2)}$. We also performed a simulation
study, similar to that of Section \ref{sec:simulation}, where we fix
$\delta_0=5.5$ and $\sigma_0=8$ and $n_1=15$ - but not $S_{1,OS}$,
$S_{1,OS,\delta_0}$ - and let $\delta$ vary from $-2\delta_0=-11$ to
$2\delta_0=11$ in steps of $0.05$ and $\sigma$ from $1$ to $20$ in
steps of $1$. Detailed results are shown in Figure \ref{fig:case}
where we plot the coverage of the confidence intervals, bias of the
mean, and variance estimate, and the average second stage sample
size. The variance bias gets as low as
$\Sexpr{round(uc.max.var.bias,2)}$, \ie it reaches the theoretical 
boundary, if the true mean effect is $\delta =0$ and the true standard
deviation $\sigma$ is larger than $8$. For smaller values of the true
standard deviation the bias is smaller in magnitude. The mean bias
goes up to $\Sexpr{round(uc.max.mean.bias,2)}$ for negative values of
the true effect size and as low as $\Sexpr{round(uc.min.mean.bias,2)}$
for positive values of the true effect size. Our simulations suggest that
the maximum of the absolute bias is reached when the true standard
deviation is close to the initial assumptions (\ie $\sigma \approx s =
8$) and the true effect size is around plus or minus the initial
effect size assumptions (\ie $\delta \approx -d = -5.5$ or $\delta
\approx d = 5.5$). 

If the sample size reassessment is based on the adjusted variance
estimate, the absolute bias of the variance and mean estimate will be
even larger taking values up to $\Sexpr{round(max.var.bias,2)}$ for the
variance and up to $\Sexpr{round(max.mean.bias,2)}$ for the mean,
respectively. 

% In terms of coverage probabilities for the confidence interval around
% the mean estimate our simulation results show 


% In Figure bla. 



% In a systematic review Pittler report observerd mean differences
% between $4$ and $17$ with standard deviations between $3$ and $5$

% \Section{Appendix: Detailed results for the case study}
% \label{sec:app}




<<eval=T,echo=F>>=
lverbose = function(variable,value){
    if(variable == "s"){
        sapply(value,function(val) substitute(paste(delta[0], " = 5.5, " ,sigma[0], " = ",foo,", ",sep=''),list(foo=val,n1=ceiling((15/34)*zss(val,5.5,.025,.2)))))
    } else {
        label_parsed(variable,label_both(variable,value))
    }
}

tcasesim <- casesim

tcasesim <- subset(tcasesim, sigma %in% (c(1:5)*2) )
tupd <- ggplot(tcasesim,mapping=aes(x=delta,y=.025-upper.prob)) +
    geom_line(y=0,colour='gray') +
    geom_path(lty=2) + #geom_point(shape='u') +
    geom_path(aes(y=.025-lower.prob),lty=3) + #geom_point(aes(y=.025-lower.prob),shape='l') +
    geom_path(aes(y=.05-total.prob)) + #geom_point(aes(y=.05-total.prob),shape='t') +
    facet_grid(s~sigma,labeller=lverbose) + theme_bw() + ylim(-.02,.01) + xlab(expression(delta)) + ylab('[%]')
tupd.uc <- ggplot(tcasesim,mapping=aes(x=delta,y=.025-uc.upper.prob)) +
    geom_line(y=0,colour='gray') +
    geom_path(lty=2) + # geom_point(shape='u') +
    geom_path(aes(y=.025-uc.lower.prob),lty=3) + #geom_point(aes(y=.025-uc.lower.prob),shape='l') +
    geom_path(aes(y=.05-uc.total.prob)) + #geom_point(aes(y=.05-uc.total.prob),shape='t') +
    facet_grid(s~sigma,labeller=lverbose) + theme_bw()+  ylim(-.02,.01) + xlab(expression(delta)) + ylab('%-points')
tupd.variance.bias <- ggplot(tcasesim,mapping=aes(x=delta,y=variance.bias)) +
    geom_line(y=0,colour='gray') + geom_path(aes(y=bound),color="red") +
  geom_path(lty=1) + geom_path(aes(y=uc.variance.bias),lty=2) +#geom_point(shape='V') + geom_point(aes(y=mean.bias),shape='M') +
  facet_grid(s~sigma,labeller=lverbose) + theme_bw() + xlab(expression(delta)) + ylab('Bias')
tupd.mean.bias <- ggplot(tcasesim,mapping=aes(x=delta,y=mean.bias)) + geom_path(lty=1)+
  geom_line(y=0,colour='gray') + geom_path(aes(y=mean.upper.bias),lty=3,col='red') + geom_path(aes(y=mean.lower.bias),lty=3,col='red') +
  geom_path(aes(y=uc.mean.bias),lty=2) +
  facet_grid(s~sigma,labeller=lverbose) + theme_bw()  + xlab(expression(delta)) + ylab('Bias') + ggtitle('Mean Bias') # +  ylim(-.2,.2)
tupd.mean.bias.sem <- ggplot(tcasesim,mapping=aes(x=delta,y=mean.bias/(sigma/sqrt(n1)))) +
  geom_line(y=0,colour='gray') +  
  geom_path(lty=1) + geom_path(aes(y=uc.mean.bias/(sigma/sqrt(n1))),lty=2) + 
  facet_grid(s~sigma,labeller=lverbose) + theme_bw() + xlab(expression(delta)) + ylab('bias')+ggtitle('Mean Bias (SEM Scaled)')
tupd.ass <- ggplot(tcasesim,mapping=aes(x=delta,y=(mean.m1+n1))) +
  geom_line(y=0,colour='gray') +  
  geom_path(lty=1) + geom_path(aes(y=uc.mean.m1+n1),lty=2) +#geom_point(shape='V') +geom_point(aes(y=uc.mean.bias),shape='M') +
  facet_grid(s~sigma,labeller=lverbose) + theme_bw() + xlab(expression(delta)) + ylab('ASN')+ggtitle('ASN')+ylim(0,70)

multiplot(tupd,tupd.mean.bias,tupd.variance.bias,
          titles=c("Actual - nominal coverage probabilities",
              "Mean Bias",
              "Variance Bias") #,
                                        #"Average Sample Number")
          )




@ 

\bibliography{imsrefsjoined}
\bibliographystyle{plain}


\end{document}


<<eval=F,echo=F>>=
n1 <- 15
X <- replicate(1000,rnorm(n1))
Y <- replicate(1000,rnorm(n1))
Xm <- colMeans(X)
Ym <- colMeans(Y)
md <- Xm-Ym
Xc <- sweep(X,2,Xm)
Yc <- sweep(Y,2,Ym)
Xs <- colSums(Xc^2)
Ys <- colSums(Yc^2)
XYm <- colMeans(rbind(X,Y))
XYc <- sweep(rbind(X,Y),2,XYm)
XYs <- colSums(XYc^2)/(2*n1-1)
XYs - (Xs + Ys + (n1/2)*md^2)/(2*n1-1)


@ 

<<eval=F,include=F,echo=F>>=

v <- expand.grid(delta=seq(0,2*d,length.out=200),sigma=seq(1,20,length.out=200))

mean.bias <- mclapply(1:nrow(v),function(i) c(v[i,],cond.bias(s1o,n1,delta=v[i,1],sigma=v[i,2])))

mean.bias <- lapply(mean.bias,unlist)
mean.bias <- as.data.frame(do.call(rbind,mean.bias))
colnames(mean.bias)[3] <- 'bias'


f <- ggplot(mean.bias,aes(x=sigma,y=delta,z=bias))+ geom_tile(aes(fill=bias)) + stat_contour(aes(colour=..level..)) + scale_fill_gradient(low='red',high='green')
direct.label(f)

out <- matrix(mean.bias$bias,ncol=length(unique(mean.bias$sigma)),
              nrow=length(unique(mean.bias$delta)))
pdf('persmb.pdf')
persp(unique(mean.bias$delta),unique(mean.bias$sigma),out,theta=130,phi=20,xlab=expression(delta),ylab=expression(sigma),zlab="Expected Bias")
dev.off()
@ 
